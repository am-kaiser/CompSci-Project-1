\section{Introduction} \label{sec:introduction}

The focus of this article is to discuss some commonly used supervised learning techniques. \newline \newline
We start with a linear regression model. It is a model that predicts a response given an input vector and introduces a learnable parameter that is linear to an input variable. Though it is called linear, it can model nonlinear functions. A combination of fixed nonlinear functions of input variables serves as a basis function to extend linear regression capability. To estimate the statistical model, we use two commonly used techniques. The first technique uses an exact equation for the learnable parameter obtained by minimizing the mean-squared error. This can be computationally costly since it involves calculating the matrix inverse. The second approach, commonly used for large data sets, uses stochastic gradient descent. We also explore both methods using shrinkage methods with L1 and L2 regularization. Ultimately, we want to obtain a statistical model that can map a new input variable to a response with acceptable accuracy. \newline \newline
We explore the power of linear regression using a typical test function such as the Franke function. We use two sampling techniques to analyze the various linear regression model. For bias and variance analysis, we use the bootstrap sampling method. To evaluate the MSE of the linear regression models, we use k-fold cross-validation. \newline \newline
Another type of supervised learning is classification models. For this case, we explore logistic regression and support vector machines. We use the Wisconsin cancer data trained under logistic regression and support vector machines. The optimization or training uses stochastic gradient descent with mini-batches for logistic regression. The classification models were trained on the cancer data using various hyperparameters such as minibatch size, number of epochs, and learning rate. For classification of the continuous-valued output, the logistic regression uses a decision boundary. In the case of SVM classification, we utilize the built-in functionality of scikit. \newline \newline
For each type of supervised learning in the following section, we start with a theoretical discussion, followed by results and discussion. \newline \newline
The code can be found in our \href{https://github.com/am-kaiser/CompSci-Project-1}{GitHub repository}.
