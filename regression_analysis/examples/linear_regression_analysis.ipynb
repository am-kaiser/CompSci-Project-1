{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c1ea9a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-17T20:26:49.729908Z",
     "start_time": "2021-11-17T20:26:49.723956Z"
    }
   },
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6c2fdd27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T15:34:10.005709Z",
     "start_time": "2021-11-30T15:34:09.985443Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6cedf291",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T15:34:11.624291Z",
     "start_time": "2021-11-30T15:34:10.655366Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of processors:  8\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from regression_analysis.fit_model import linear_regression\n",
    "from regression_analysis.utils import franke\n",
    "from regression_analysis.utils.plots import triangulation_for_triheatmap as triheatmap\n",
    "from regression_analysis.fit_model.apply_linear_regression import plot_stat, apply_regression\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib.tri import Triangulation\n",
    "from matplotlib.ticker import AutoMinorLocator, MultipleLocator\n",
    "from matplotlib import cm\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "\n",
    "import ipywidgets as widget\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "\n",
    "import glob as glob\n",
    "from IPython.display import Image, display, HTML, Video\n",
    "\n",
    "import multiprocessing as mp\n",
    "\n",
    "import os\n",
    "if not os.path.exists('data'):\n",
    "    os.makedirs('data')\n",
    "#note my bootstrap can be wrong. \n",
    "\n",
    "print(\"Number of processors: \", mp.cpu_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a609d53b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-17T20:24:29.410589Z",
     "start_time": "2021-11-17T20:24:29.408506Z"
    }
   },
   "source": [
    "# Demo for applying regression to Franke data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9b584e68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T14:15:00.857613Z",
     "start_time": "2021-11-30T14:15:00.844063Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2195347797082343\n"
     ]
    }
   ],
   "source": [
    "n = 100 #number of data points along each axis. Total data points = n*n\n",
    "x1 = np.linspace(0,1,n)\n",
    "x2 = np.linspace(0,1,n)\n",
    "xx1, xx2 = np.meshgrid(x1, x2)\n",
    "xx1 = xx1.reshape((n*n),1)\n",
    "xx2 = xx2.reshape((n*n),1)\n",
    "\n",
    "y = franke.Franke(xx1, xx2, noise_var=0.0) #zero mean gaussian noise has variance = var\n",
    "print(np.max(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c238ad66",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T14:15:00.956879Z",
     "start_time": "2021-11-30T14:15:00.945749Z"
    }
   },
   "outputs": [],
   "source": [
    "#create linear regression object by passing input and output data\n",
    "linear_reg = linear_regression.linear_regression2D(xx1, xx2, y) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ed0579",
   "metadata": {},
   "source": [
    "## Apply OLS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9e297d82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T14:19:11.593200Z",
     "start_time": "2021-11-30T14:19:11.526735Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "own OLS\n",
      "Train MSE 0.001410114522628253\n",
      "Test MSE 0.0013356872643718006\n",
      "Train R2 0.9748089296279824\n",
      "Test R2 0.9738781746727827\n",
      "Train bias 0.05597676088407167\n",
      "Test bias 0.051133332916578754\n",
      "Train model variance 0.054566646365002545\n",
      "Test model variance 0.05029718432621037\n",
      "\n",
      "Scikit OLS\n",
      "Train MSE 0.0013788757093671539\n",
      "Test MSE 0.0016198325355494807\n",
      "Train R2 0.9751005680009313\n",
      "Test R2 0.9713652027302864\n",
      "Train bias 0.05537779775131928\n",
      "Test bias 0.056568689967200735\n",
      "Train model variance 0.0539989220419531\n",
      "Test model variance 0.054898671313521545\n"
     ]
    }
   ],
   "source": [
    "print(\"own OLS\")\n",
    "linear_reg.apply_leastsquares(order=5, test_ratio=0.1, reg_method=\"ols\")\n",
    "print(\"Train MSE\", linear_reg.trainMSE)\n",
    "print(\"Test MSE\", linear_reg.testMSE)\n",
    "print(\"Train R2\", linear_reg.trainR2)\n",
    "print(\"Test R2\", linear_reg.testR2)\n",
    "print(\"Train bias\", linear_reg.trainbias)\n",
    "print(\"Test bias\", linear_reg.testbias)\n",
    "print(\"Train model variance\", linear_reg.trainvar)\n",
    "print(\"Test model variance\", linear_reg.testvar)\n",
    "\n",
    "print('\\n'+ \"Scikit OLS\")\n",
    "linear_reg.apply_leastsquares(order=5, test_ratio=0.1, reg_method=\"scikit_ols\")\n",
    "print(\"Train MSE\", linear_reg.trainMSE)\n",
    "print(\"Test MSE\", linear_reg.testMSE)\n",
    "print(\"Train R2\", linear_reg.trainR2)\n",
    "print(\"Test R2\", linear_reg.testR2)\n",
    "print(\"Train bias\", linear_reg.trainbias)\n",
    "print(\"Test bias\", linear_reg.testbias)\n",
    "print(\"Train model variance\", linear_reg.trainvar)\n",
    "print(\"Test model variance\", linear_reg.testvar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "27eaee7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T14:19:13.403952Z",
     "start_time": "2021-11-30T14:19:12.916809Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE 0.0014012635537023917\n",
      "Test MSE 0.0014038325530881385\n",
      "Train R2 0.9747278519261993\n",
      "Test R2 0.9747232446818235\n",
      "Train bias 0.05730505912325425\n",
      "Test bias 0.05744214833559367\n",
      "Train model variance 0.055857833046078116\n",
      "Test model variance 0.055950081332726644\n"
     ]
    }
   ],
   "source": [
    "linear_reg.apply_leastsquares_bootstrap(order=5, test_ratio=0.1, n_boots=30, reg_method=\"ols\")\n",
    "print(\"Train MSE\", linear_reg.trainMSE)\n",
    "print(\"Test MSE\", linear_reg.testMSE)\n",
    "print(\"Train R2\", linear_reg.trainR2)\n",
    "print(\"Test R2\", linear_reg.testR2)\n",
    "print(\"Train bias\", linear_reg.trainbias)\n",
    "print(\"Test bias\", linear_reg.testbias)\n",
    "print(\"Train model variance\", linear_reg.trainvar)\n",
    "print(\"Test model variance\", linear_reg.testvar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bfa940",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-17T20:27:44.344810Z",
     "start_time": "2021-11-17T20:27:44.341402Z"
    }
   },
   "source": [
    "## Apply OLS with cross validation sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2daa8a14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T14:19:15.150408Z",
     "start_time": "2021-11-30T14:19:14.985706Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE 0.0014022085274557465\n",
      "Test MSE 0.001408637398800588\n",
      "Train R2 0.9747332275350148\n",
      "Test R2 0.9745853552705375\n",
      "Train bias 1.5433252503132483e-12\n",
      "Test bias 1.4136511074800407e-05\n",
      "Train model variance 0.005380822539170242\n",
      "Test model variance 0.005642200825399792\n"
     ]
    }
   ],
   "source": [
    "linear_reg.apply_leastsquares_crossvalidation(order=5, kfolds=10, reg_method=\"ols\")\n",
    "print(\"Train MSE\", linear_reg.trainMSE)\n",
    "print(\"Test MSE\", linear_reg.testMSE)\n",
    "print(\"Train R2\", linear_reg.trainR2)\n",
    "print(\"Test R2\", linear_reg.testR2)\n",
    "print(\"Train bias\", linear_reg.trainbias)\n",
    "print(\"Test bias\", linear_reg.testbias)\n",
    "print(\"Train model variance\", linear_reg.trainvar)\n",
    "print(\"Test model variance\", linear_reg.testvar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7855d868",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-17T20:28:20.371789Z",
     "start_time": "2021-11-17T20:28:20.365778Z"
    }
   },
   "source": [
    "## Apply Ridge regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "44f21a63",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T14:19:18.709664Z",
     "start_time": "2021-11-30T14:19:18.648595Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "own ridge\n",
      "Train MSE 0.005679989981071026\n",
      "Test MSE 0.005544646534039737\n",
      "Train R2 0.8980408048898912\n",
      "Test R2 0.8964607810060322\n",
      "Train bias 0.05570846965469222\n",
      "Test bias 0.0535597156100963\n",
      "Train model variance 0.048066553618386965\n",
      "Test model variance 0.048245268422475826\n",
      "\n",
      "scikit ridge\n",
      "Train MSE 0.0056605767742129495\n",
      "Test MSE 0.005760812007796378\n",
      "Train R2 0.8974288920951614\n",
      "Test R2 0.9011282135998352\n",
      "Train bias 0.055186861435517494\n",
      "Test bias 0.05826589648824006\n",
      "Train model variance 0.0475718594824065\n",
      "Test model variance 0.04942104666735711\n"
     ]
    }
   ],
   "source": [
    "print(\"own ridge\")\n",
    "linear_reg.apply_leastsquares(order=5, test_ratio=0.1, reg_method=\"ridge\", lmbda=0.9)\n",
    "print(\"Train MSE\", linear_reg.trainMSE)\n",
    "print(\"Test MSE\", linear_reg.testMSE)\n",
    "print(\"Train R2\", linear_reg.trainR2)\n",
    "print(\"Test R2\", linear_reg.testR2)\n",
    "print(\"Train bias\", linear_reg.trainbias)\n",
    "print(\"Test bias\", linear_reg.testbias)\n",
    "print(\"Train model variance\", linear_reg.trainvar)\n",
    "print(\"Test model variance\", linear_reg.testvar)\n",
    "\n",
    "print('\\n'+\"scikit ridge\")\n",
    "linear_reg.apply_leastsquares(order=5, test_ratio=0.1, reg_method=\"scikit_ridge\", lmbda=0.9)\n",
    "print(\"Train MSE\", linear_reg.trainMSE)\n",
    "print(\"Test MSE\", linear_reg.testMSE)\n",
    "print(\"Train R2\", linear_reg.trainR2)\n",
    "print(\"Test R2\", linear_reg.testR2)\n",
    "print(\"Train bias\", linear_reg.trainbias)\n",
    "print(\"Test bias\", linear_reg.testbias)\n",
    "print(\"Train model variance\", linear_reg.trainvar)\n",
    "print(\"Test model variance\", linear_reg.testvar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fb6486",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-17T20:28:59.997409Z",
     "start_time": "2021-11-17T20:28:59.992330Z"
    }
   },
   "source": [
    "## Apply Ridge regression with bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "159e173d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T14:19:22.832986Z",
     "start_time": "2021-11-30T14:19:22.198325Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE 0.0056549255219222085\n",
      "Test MSE 0.005727142736381949\n",
      "Train R2 0.8978382042630967\n",
      "Test R2 0.8972205494906131\n",
      "Train bias 0.057194745158677944\n",
      "Test bias 0.05766738525774298\n",
      "Train model variance 0.04934595134535384\n",
      "Test model variance 0.04964790921825936\n"
     ]
    }
   ],
   "source": [
    "linear_reg.apply_leastsquares_bootstrap(order=5, test_ratio=0.1, n_boots=30, reg_method=\"ridge\", lmbda=0.9)\n",
    "print(\"Train MSE\", linear_reg.trainMSE)\n",
    "print(\"Test MSE\", linear_reg.testMSE)\n",
    "print(\"Train R2\", linear_reg.trainR2)\n",
    "print(\"Test R2\", linear_reg.testR2)\n",
    "print(\"Train bias\", linear_reg.trainbias)\n",
    "print(\"Test bias\", linear_reg.testbias)\n",
    "print(\"Train model variance\", linear_reg.trainvar)\n",
    "print(\"Test model variance\", linear_reg.testvar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2375111",
   "metadata": {},
   "source": [
    "## Apply Ridge regression with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1c3c4006",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T14:19:26.407897Z",
     "start_time": "2021-11-30T14:19:26.249757Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE 0.003587477120332968\n",
      "Test MSE 0.0035964259921588784\n",
      "Train R2 0.935355194380006\n",
      "Test R2 0.9350327987862563\n",
      "Train bias 8.265432151216285e-07\n",
      "Test bias -0.00017421748001882\n",
      "Train model variance 0.005057123042222968\n",
      "Test model variance 0.004505249032630451\n"
     ]
    }
   ],
   "source": [
    "linear_reg.apply_leastsquares_crossvalidation(order=5, kfolds=10, reg_method=\"ridge\", lmbda=0.1)\n",
    "print(\"Train MSE\", linear_reg.trainMSE)\n",
    "print(\"Test MSE\", linear_reg.testMSE)\n",
    "print(\"Train R2\", linear_reg.trainR2)\n",
    "print(\"Test R2\", linear_reg.testR2)\n",
    "print(\"Train bias\", linear_reg.trainbias)\n",
    "print(\"Test bias\", linear_reg.testbias)\n",
    "print(\"Train model variance\", linear_reg.trainvar)\n",
    "print(\"Test model variance\", linear_reg.testvar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e1362a",
   "metadata": {},
   "source": [
    "## Apply Lasso regression: Not working properly. High R2 value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31dd814f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-28T16:37:57.957401Z",
     "start_time": "2021-11-28T16:37:57.719836Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "23a96853",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T14:19:29.206810Z",
     "start_time": "2021-11-30T14:19:29.127692Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.00000000e-04 1.77827941e-04 3.16227766e-04 5.62341325e-04\n",
      " 1.00000000e-03 1.77827941e-03 3.16227766e-03 5.62341325e-03\n",
      " 1.00000000e-02 1.77827941e-02 3.16227766e-02 5.62341325e-02\n",
      " 1.00000000e-01 1.77827941e-01 3.16227766e-01 5.62341325e-01\n",
      " 1.00000000e+00]\n",
      "Test MSE 0.005605980127328259\n",
      "Test MSE 0.006387285336819054\n",
      "Test MSE 0.006466917047918432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amandink/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.038049553612844, tolerance: 0.14923339135420746\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/amandink/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.1484955699905157, tolerance: 0.14872040343271664\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/amandink/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.0479814453819642, tolerance: 0.14889035130420625\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/amandink/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7341053033750171, tolerance: 0.14857540982740702\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE 0.00879665630831108\n",
      "Test MSE 0.00804591905954383\n",
      "Test MSE 0.011680162001830675\n",
      "Test MSE 0.015200114154789121\n",
      "Test MSE 0.01685691044638075\n",
      "Test MSE 0.02161940954013454\n",
      "Test MSE 0.02843972073321338\n",
      "Test MSE 0.04735467604211118\n",
      "Test MSE 0.05306646639450158\n",
      "Test MSE 0.05887907875318154\n",
      "Test MSE 0.09276534384251858\n",
      "Test MSE 0.15928165814590556\n",
      "Test MSE 0.17374734912853426\n",
      "Test MSE 0.16399525382879687\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nprint(\"Train MSE\", linear_reg.trainMSE)\\nprint(\"Test MSE\", linear_reg.testMSE)\\nprint(\"Train R2\", linear_reg.trainR2)\\nprint(\"Test R2\", linear_reg.testR2)\\nprint(\"Train bias\", linear_reg.trainbias)\\nprint(\"Test bias\", linear_reg.testbias)\\nprint(\"Train model variance\", linear_reg.trainvar)\\nprint(\"Test model variance\", linear_reg.testvar)\\n'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lam = np.logspace(-4,0,17)\n",
    "print(lam)\n",
    "for lmbda in lam:\n",
    "    linear_reg.apply_leastsquares(order=5, test_ratio=0.1, reg_method=\"scikit_lasso\", lmbda=lmbda)\n",
    "    print(\"Test MSE\", linear_reg.testMSE)\n",
    "\n",
    "\"\"\"\n",
    "print(\"Train MSE\", linear_reg.trainMSE)\n",
    "print(\"Test MSE\", linear_reg.testMSE)\n",
    "print(\"Train R2\", linear_reg.trainR2)\n",
    "print(\"Test R2\", linear_reg.testR2)\n",
    "print(\"Train bias\", linear_reg.trainbias)\n",
    "print(\"Test bias\", linear_reg.testbias)\n",
    "print(\"Train model variance\", linear_reg.trainvar)\n",
    "print(\"Test model variance\", linear_reg.testvar)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237dc8dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-28T16:22:48.026552Z",
     "start_time": "2021-11-28T16:22:47.970142Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a1cc1b6e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-19T14:49:53.922397Z",
     "start_time": "2021-11-19T14:49:53.915295Z"
    }
   },
   "source": [
    "# Regression Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9a9dbdc9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T14:19:34.185079Z",
     "start_time": "2021-11-30T14:19:34.170912Z"
    }
   },
   "outputs": [],
   "source": [
    "# For all methods we apply the following parameters\n",
    "order = np.arange(0,13)\n",
    "num_points = np.array([10, 20, 30, 40, 50])\n",
    "noise_var = np.array([0.0, 0.05, 0.1, 0.15, 0.2])\n",
    "test_ratio = np.round(np.arange(1,5)*0.1, 2)\n",
    "\n",
    "n_boots = np.array([5, 10], dtype=int)\n",
    "k_folds = np.array([5, 10], dtype=int)\n",
    "ridge_lambda = np.array([0.001, 0.01, 0.1, 1.0])\n",
    "lasso_lambda = np.array([0.00001, 0.0001, 0.001, 0.01])\n",
    "\n",
    "# Parameters for stochastic gradient descent\n",
    "learn_rates = np.array([0.001, 0.01, 0.1, 1.0])\n",
    "num_min_batches = np.array([2, 5, 10, 50])\n",
    "epochs = np.array([10, 50, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7c334405",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T14:19:35.584824Z",
     "start_time": "2021-11-30T14:19:35.553033Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save values in numpy file format\n",
    "np.save(\"data_linear_regression/order.npy\", order)\n",
    "np.save(\"data_linear_regression/num_points.npy\", num_points)\n",
    "np.save(\"data_linear_regression/noise_var.npy\", noise_var)\n",
    "np.save(\"data_linear_regression/test_ratio.npy\", test_ratio)\n",
    "np.save(\"data_linear_regression/k_folds.npy\", k_folds)\n",
    "np.save(\"data_linear_regression/n_boots.npy\", n_boots)\n",
    "np.save(\"data_linear_regression/ridge_lambda.npy\", ridge_lambda)\n",
    "np.save(\"data_linear_regression/lasso_lambda.npy\", lasso_lambda)\n",
    "np.save(\"data_linear_regression/learn_rates.npy\", learn_rates)\n",
    "np.save(\"data_linear_regression/num_min_batches.npy\", num_min_batches)\n",
    "np.save(\"data_linear_regression/epochs.npy\", epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749a0864",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-24T09:44:32.230857Z",
     "start_time": "2021-11-24T09:44:31.913116Z"
    }
   },
   "source": [
    "Perform\n",
    "* Ordinary Least Squares(OLS) with scikit-learn test train split, own bootstrap, own cross-validation\n",
    "* Ridge Regression(RR) with scikit-learn test train split, own bootstrap, own cross-validation\n",
    "* Scikit Lasso Regression(LR) with scikit-learn test train split, own bootstrap, own cross-validation\n",
    "* Scikit OLS with scikit-learn test train split. Note: this is just for comparing OLS to Scikit-OLS\n",
    "* Scikit RR with scikit-learn test train split. Note: this is just for comparing OLS to Scikit-OLS\n",
    "\n",
    "and save output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4e6c21b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-29T13:42:18.520097Z",
     "start_time": "2021-11-29T13:42:05.184340Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 5, 5, 1, 4, 1, 1, 2, 1, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "# Define for which regression methods and resampling techniques the statistical indicators should be calculated\n",
    "\"\"\"methods = [\"ols\", \"ols_bootstrap\", \"ols_crossvalidation\", \"ridge\", \n",
    "           \"ridge_bootstrap\", \"ridge_crossvalidation\", \"lasso\", \"lasso_bootstrap\",\n",
    "           \"lasso_crossvalidation\", \"ols_sgd\", \"ols_bootstrap_sgd\", \"ols_crossvalidation_sgd\", \"ridge_sgd\", \"ridge_bootstrap_sgd\"\n",
    "            \"ridge_crossvalidation_sgd\", ]\"\"\"\n",
    "methods = [\"ridge_crossvalidation\"]\n",
    "\n",
    "# Loop over specified methods\n",
    "for method in methods:\n",
    "    if(method == \"ols_crossvalidation\" or method == \"ridge_crossvalidation\" or method == \"lasso_crossvalidation\"):\n",
    "        test_ratio_array = np.ones(1)*0.1\n",
    "    if(method != \"ols_bootstrap\" and method != \"ridge_bootstrap\" and method != \"lasso_bootstrap\"):\n",
    "        n_boots = np.ones(1, dtype=int)\n",
    "    if(method != \"ols_crossvalidation\" and method != \"ridge_crossvalidation\" and method != \"lasso_crossvalidation\"):\n",
    "        k_folds = np.ones(1, dtype=int)\n",
    "    if(method != \"ridge\" and method != \"ridge_bootstrap\" and method != \"ridge_crossvalidation\"):\n",
    "        ridge_lambda = np.ones(1)\n",
    "    if(method != \"lasso\" and method != \"lasso_bootstrap\" and method != \"lasso_crossvalidation\"):\n",
    "        lasso_lambda = np.ones(1)\n",
    "    # Calculate statistical indicators\n",
    "    train_MSE, test_MSE, train_R2, test_R2, test_bias, test_var = apply_regression(order, num_points, noise_var, \n",
    "                                                                                   test_ratio_array, \n",
    "                                                                                   n_boots=n_boots, \n",
    "                                                                                   k_folds=k_folds, \n",
    "                                                                                   ridge_lambda=ridge_lambda, \n",
    "                                                                                   lasso_lambda=lasso_lambda, \n",
    "                                                                                   reg_type=method)\n",
    "    # Save output\n",
    "    np.save(\"data_linear_regression/train_MSE\"+str(method)+\".npy\", train_MSE)\n",
    "    np.save(\"data_linear_regression/test_MSE\"+str(method)+\".npy\", test_MSE)\n",
    "    np.save(\"data_linear_regression/train_R2\"+str(method)+\".npy\", train_R2)\n",
    "    np.save(\"data_linear_regression/test_R2\"+str(method)+\".npy\", test_R2)\n",
    "    np.save(\"data_linear_regression/test_bias\"+str(method)+\".npy\", test_bias)\n",
    "    np.save(\"data_linear_regression/test_variance\"+str(method)+\".npy\", test_var)\n",
    "    \n",
    "    # To track loop progress print size of MSE output\n",
    "    print(train_MSE.shape)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a400f61d",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-11-30T12:24:30.367Z"
    },
    "code_folding": []
   },
   "source": [
    "pool = mp.Pool(processes=3)\n",
    "methods = methods = [\"e\",\"e\",\"d\", \"d\", \"s\",\"d\", \"d\", \"s\", \"ols\", \"ridge_crossvalidation\", \"lasso\", \"lasso_bootstrap\",\n",
    "           \"lasso_crossvalidation\", \"ols_bootstrap\", \"ols_crossvalidation\", \"ridge\", \n",
    "           \"ridge_bootstrap\"]\n",
    "#methods = methods = [\"e\",\"e\",\"d\", \"d\", \"s\",\"d\", \"d\", \"s\", \"lasso\", \"lasso_bootstrap\",\n",
    "#           \"lasso_crossvalidation\"]\n",
    "def run_regression(method):\n",
    "    print(method)\n",
    "    order = np.load(\"data/order.npy\")\n",
    "    num_points = np.load(\"data/num_points.npy\")\n",
    "    noise_var = np.load(\"data/noise_var.npy\")\n",
    "    test_ratio_array = np.load(\"data/test_ratio_array.npy\")\n",
    "    k_folds = np.load(\"data/k_folds.npy\")\n",
    "    n_boots = np.load(\"data/n_boots.npy\")\n",
    "    ridge_lambda = np.load(\"data/ridge_lambda.npy\")\n",
    "    lasso_lambda = np.load(\"data/lasso_lambda.npy\")\n",
    "    \n",
    "    if(method == \"ols_crossvalidation\" or method == \"ridge_crossvalidation\" or method == \"lasso_crossvalidation\"):\n",
    "        test_ratio_array = np.ones(1)*0.1\n",
    "    if(method != \"ols_bootstrap\" and method != \"ridge_bootstrap\" and method != \"lasso_bootstrap\"):\n",
    "        n_boots = np.ones(1, dtype=int)\n",
    "    if(method != \"ols_crossvalidation\" and method != \"ridge_crossvalidation\" and method != \"lasso_crossvalidation\"):\n",
    "        k_folds = np.ones(1, dtype=int)\n",
    "    if(method != \"ridge\" and method != \"ridge_bootstrap\" and method != \"ridge_crossvalidation\"):\n",
    "        ridge_lambda = np.ones(1)\n",
    "    if(method != \"lasso\" and method != \"lasso_bootstrap\" and method != \"lasso_crossvalidation\"):\n",
    "        lasso_lambda = np.ones(1)\n",
    "    # Calculate statistical indicators\n",
    "    train_MSE, test_MSE, train_R2, test_R2, test_bias, test_var = apply_regression(order, num_points, noise_var, \n",
    "                                                                                   test_ratio_array, \n",
    "                                                                                   n_boots=n_boots, \n",
    "                                                                                   k_folds=k_folds, \n",
    "                                                                                   ridge_lambda=ridge_lambda, \n",
    "                                                                                   lasso_lambda=lasso_lambda, \n",
    "                                                                                   reg_type=method)\n",
    "    # Save output\n",
    "    test_ratio_array=np.load(\"data/test_ratio.npy\")\n",
    "    print(lasso_lambda)\n",
    "    ridge_lambda=np.load(\"data/ridge_lambda.npy\")\n",
    "    lasso_lambda=np.load(\"data/lasso_lambda.npy\")\n",
    "    k_folds=np.load(\"data/k_folds.npy\")\n",
    "    n_boots=np.load(\"data/n_boots.npy\")\n",
    "    np.save(\"data/train_MSE\"+str(method)+\".npy\", train_MSE)\n",
    "    np.save(\"data/test_MSE\"+str(method)+\".npy\", test_MSE)\n",
    "    np.save(\"data/train_R2\"+str(method)+\".npy\", train_R2)\n",
    "    np.save(\"data/test_R2\"+str(method)+\".npy\", test_R2)\n",
    "    np.save(\"data/test_bias\"+str(method)+\".npy\", test_bias)\n",
    "    np.save(\"data/test_variance\"+str(method)+\".npy\", test_var)\n",
    "    # To track loop progress print size of MSE output\n",
    "    print(train_MSE.shape)\n",
    "    print(\"finished \", method)\n",
    "    return 0\n",
    "    \n",
    "[pool.map(run_regression, methods)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72452284",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T14:20:45.845471Z",
     "start_time": "2021-11-30T14:20:45.830412Z"
    }
   },
   "source": [
    "## Widget to compare all experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bd3f0506",
   "metadata": {},
   "outputs": [],
   "source": [
    "order = np.load(\"data_linear_regression/order.npy\")\n",
    "num_points = np.load(\"data_linear_regression/num_points.npy\")\n",
    "noise_var = np.load(\"data_linear_regression/noise_var.npy\")\n",
    "test_ratio = np.load(\"data_linear_regression/test_ratio.npy\")\n",
    "k_folds = np.load(\"data_linear_regression/k_folds.npy\")\n",
    "n_boots = np.load(\"data_linear_regression/n_boots.npy\")\n",
    "ridge_lambda = np.load(\"data_linear_regression/ridge_lambda.npy\")\n",
    "lasso_lambda = np.load(\"data_linear_regression/lasso_lambda.npy\")\n",
    "learn_rates= np.load(\"data_linear_regression/learn_rates.npy\")\n",
    "num_min_batches= np.load(\"data_linear_regression/num_min_batches.npy\")\n",
    "epochs = np.load(\"data_linear_regression/epochs.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6fb99ba3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T14:20:51.615224Z",
     "start_time": "2021-11-30T14:20:51.261876Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6d13582c34843fe8d9be26d0fc0508d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='ratio', options=(0.1, 0.2, 0.3, 0.4), value=0.1), Dropdown(descripâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function regression_analysis.fit_model.apply_linear_regression.plot_stat(ratio=0.1, num=100, stat='test MSE', method='ols', n_boot=1000, k_fold=1000, ridge_lmb=122.0, lasso_lmb=112.2, learn_rate=0.1, batch=5, epoch=50)>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"methods = [\"ols\", \"ols_bootstrap\", \"ols_crossvalidation\", \"ridge\", \n",
    "           \"ridge_bootstrap\", \"ridge_crossvalidation\", \"lasso\", \"lasso_bootstrap\",\n",
    "           \"lasso_crossvalidation\", \"ols_sgd\", \"ols_bootstrap_sgd\", \"ols_crossvalidation_sgd\", \"ridge_sgd\", \"ridge_bootstrap_sgd\"\n",
    "            \"ridge_crossvalidation_sgd\", ]\"\"\"\n",
    "methods = [\"ridge\", \"ridge_bootstrap\", \"ridge_crossvalidation\"]\n",
    "stats = [\"train MSE\", \"test MSE\", \"test R2\", \"train R2\", \"test bias\", \"test variance\"]\n",
    "\n",
    "widget.interact(plot_stat, ratio=test_ratio.tolist(), num=num_points.tolist(), stat=stats, \n",
    "                method=methods, k_fold=k_folds.tolist(), n_boot=n_boots.tolist(),\n",
    "                ridge_lmb=ridge_lambda.tolist(), lasso_lmb=lasso_lambda.tolist(), learn_rate=learn_rates.tolist(),\n",
    "                batch=num_min_batches.tolist(), epoch=epochs.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b59dec",
   "metadata": {},
   "source": [
    "# Edge cases study of OLS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3512b24f",
   "metadata": {},
   "source": [
    "## Worst case study\n",
    "What is the lowest possible MSE that we can get for data normalised to the range [0,1] such that the polynomial fitted is the best polynomial fit?\n",
    "This will happen when half of the data is 0 and the other half is 1, and if we fit a polynomial of order p such that p<<n where n is the number of data points. Then we will end up fitting a constant which is 0.5. What is MSE in this case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0d98379e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of the output is  0.5\n",
      "fitting a constant\n",
      "Train MSE 0.24999999760987654\n",
      "Test MSE 0.25000004541234566\n",
      "Train R2 -2.220446049250313e-16\n",
      "Test R2 -9.56050123290808e-07\n",
      "Test bias 0.25000004541234566\n",
      "Test model variance 4.930380657631324e-32\n",
      "fitting a 10th order polynomial\n",
      "Train MSE 0.24998423546739382\n",
      "Test MSE 0.2500184339148649\n",
      "Train R2 6.287987002950857e-05\n",
      "Test R2 -8.817693273477367e-05\n",
      "Test bias 0.25000068358936905\n",
      "Test model variance 1.578678218491479e-05\n",
      "The worst possible MSE for data normalised to range [0,1] is  0.2500184339148649 and is almost independent of the order of the polynomial used to fit such that the order of polynomial is much less than the number of data points\n"
     ]
    }
   ],
   "source": [
    "n = 1000 #number of data points along each axis. Total data points = n*n\n",
    "x1 = np.linspace(0,1,n)\n",
    "x2 = np.linspace(0,1,n)\n",
    "xx1, xx2 = np.meshgrid(x1, x2)\n",
    "xx1 = xx1.reshape((n*n),1)\n",
    "xx2 = xx2.reshape((n*n),1)\n",
    "y = np.zeros(xx1.shape)\n",
    "y[::2, :]+=1.0\n",
    "print(\"mean of the output is \", np.mean(y))\n",
    "\n",
    "print(\"fitting a constant\")\n",
    "linear_reg = linear_regression.linear_regression2D(xx1, xx2, y) \n",
    "linear_reg.apply_leastsquares(order=0, test_ratio=0.1, reg_method=\"ols\")\n",
    "\n",
    "print(\"Train MSE\", linear_reg.trainMSE)\n",
    "print(\"Test MSE\", linear_reg.testMSE)\n",
    "print(\"Train R2\", linear_reg.trainR2)\n",
    "print(\"Test R2\", linear_reg.testR2)\n",
    "print(\"Test bias\", linear_reg.testbias)\n",
    "print(\"Test model variance\", linear_reg.testvar)\n",
    "\n",
    "print(\"fitting a 10th order polynomial\")\n",
    "linear_reg.apply_leastsquares(order=10, test_ratio=0.1, reg_method=\"ols\")\n",
    "\n",
    "print(\"Train MSE\", linear_reg.trainMSE)\n",
    "print(\"Test MSE\", linear_reg.testMSE)\n",
    "print(\"Train R2\", linear_reg.trainR2)\n",
    "print(\"Test R2\", linear_reg.testR2)\n",
    "print(\"Test bias\", linear_reg.testbias)\n",
    "print(\"Test model variance\", linear_reg.testvar)\n",
    "\n",
    "print(\"The worst possible MSE for data normalised to range [0,1] is \", \n",
    "      linear_reg.testMSE, \"and is almost independent of the order of the polynomial used to fit such that the order of polynomial is much less than the number of data points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebb0114",
   "metadata": {},
   "source": [
    "## Fitting uniform random numbers\n",
    "What will happen if we use OLS to fit data which is essentially a random uniform number between 0 and 1 irrespective of the value of the dependent variables. What is the MSE in this situation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3de9ef65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of the output is  0.49967663380586685\n",
      "fitting a constant\n",
      "Train MSE 0.08339761987218385\n",
      "Test MSE 0.08358573659859046\n",
      "Train R2 -2.220446049250313e-16\n",
      "Test R2 -5.311528936680077e-06\n",
      "Test bias 0.08358573659859046\n",
      "Test model variance 0.0\n",
      "fitting a 10th order polynomial\n",
      "Train MSE 0.08344046171053035\n",
      "Test MSE 0.0831461355323776\n",
      "Train R2 7.779996337375916e-05\n",
      "Test R2 -5.487011094729155e-05\n",
      "Test bias 0.08314172673782205\n",
      "Test model variance 6.5010836658981334e-06\n"
     ]
    }
   ],
   "source": [
    "n = 1000 #number of data points along each axis. Total data points = n*n\n",
    "x1 = np.linspace(0,1,n)\n",
    "x2 = np.linspace(0,1,n)\n",
    "xx1, xx2 = np.meshgrid(x1, x2)\n",
    "xx1 = xx1.reshape((n*n),1)\n",
    "xx2 = xx2.reshape((n*n),1)\n",
    "y = np.random.uniform(size=xx1.shape)\n",
    "print(\"mean of the output is \", np.mean(y))\n",
    "\n",
    "print(\"fitting a constant\")\n",
    "linear_reg = linear_regression.linear_regression2D(xx1, xx2, y) \n",
    "linear_reg.apply_leastsquares(order=0, test_ratio=0.1, reg_method=\"ols\")\n",
    "\n",
    "print(\"Train MSE\", linear_reg.trainMSE)\n",
    "print(\"Test MSE\", linear_reg.testMSE)\n",
    "print(\"Train R2\", linear_reg.trainR2)\n",
    "print(\"Test R2\", linear_reg.testR2)\n",
    "print(\"Test bias\", linear_reg.testbias)\n",
    "print(\"Test model variance\", linear_reg.testvar)\n",
    "\n",
    "print(\"fitting a 10th order polynomial\")\n",
    "linear_reg.apply_leastsquares(order=10, test_ratio=0.1, reg_method=\"ols\")\n",
    "\n",
    "print(\"Train MSE\", linear_reg.trainMSE)\n",
    "print(\"Test MSE\", linear_reg.testMSE)\n",
    "print(\"Train R2\", linear_reg.trainR2)\n",
    "print(\"Test R2\", linear_reg.testR2)\n",
    "print(\"Test bias\", linear_reg.testbias)\n",
    "print(\"Test model variance\", linear_reg.testvar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f52f614",
   "metadata": {},
   "source": [
    "## Fitting gaussian data\n",
    "What will happen if we use OLS to fit data which is essentially a truncated gaussian number between 0 and 1 where the output is independent of the dependant variables. What is the MSE in this situation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "30a615d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of the output is  0.5000678537099417\n",
      "variance of the output is  0.009994691391200123\n",
      "fitting a constant\n",
      "Train MSE 0.010451794516680258\n",
      "Test MSE 0.010523079472809541\n",
      "Train R2 2.220446049250313e-16\n",
      "Test R2 -8.860384638653684e-06\n",
      "Test bias 0.010523079472809541\n",
      "Test model variance 2.7733391199176196e-32\n",
      "fitting a 10th order polynomial\n",
      "Train MSE 0.010455067723977168\n",
      "Test MSE 0.010488650748820771\n",
      "Train R2 6.756820360132032e-05\n",
      "Test R2 -0.00015277783858080873\n",
      "Test bias 0.01048734849574711\n",
      "Test model variance 7.431630420245591e-07\n",
      "mean of the output is  0.4999965383152064\n",
      "variance of the output is  0.03913758372608158\n",
      "fitting a constant\n",
      "Train MSE 0.039110203548773904\n",
      "Test MSE 0.03938400825656102\n",
      "Train R2 0.0\n",
      "Test R2 -7.451533674540656e-07\n",
      "Test bias 0.03938400825656102\n",
      "Test model variance 1.1093356479670479e-31\n",
      "fitting a 10th order polynomial\n",
      "Train MSE 0.039090735837762035\n",
      "Test MSE 0.03953993273952372\n",
      "Train R2 6.913241521333546e-05\n",
      "Test R2 -0.00012861770341032752\n",
      "Test bias 0.039534930983779706\n",
      "Test model variance 2.7893638574212583e-06\n",
      "mean of the output is  0.4996874570773295\n",
      "variance of the output is  0.0754244767635124\n",
      "fitting a constant\n",
      "Train MSE 0.07538749916562525\n",
      "Test MSE 0.07575730533730103\n",
      "Train R2 0.0\n",
      "Test R2 -3.985480197199465e-06\n",
      "Test bias 0.07575730533730103\n",
      "Test model variance 4.930380657631324e-32\n",
      "fitting a 10th order polynomial\n",
      "Train MSE 0.07541302877206985\n",
      "Test MSE 0.07549240206956769\n",
      "Train R2 5.289702485022918e-05\n",
      "Test R2 -1.0765788129640796e-05\n",
      "Test bias 0.07549161007307688\n",
      "Test model variance 4.120548729084531e-06\n",
      "mean of the output is  0.49959224423437265\n",
      "variance of the output is  0.10592400195508202\n",
      "fitting a constant\n",
      "Train MSE 0.10591285335523948\n",
      "Test MSE 0.1060243680410312\n",
      "Train R2 1.1102230246251565e-16\n",
      "Test R2 -2.7057406977171183e-06\n",
      "Test bias 0.1060243680410312\n",
      "Test model variance 0.0\n",
      "fitting a 10th order polynomial\n",
      "Train MSE 0.10586327142124655\n",
      "Test MSE 0.10640777278400163\n",
      "Train R2 8.173126419008803e-05\n",
      "Test R2 -0.00018956712543483079\n",
      "Test bias 0.10639358496636409\n",
      "Test model variance 8.742199420211124e-06\n",
      "mean of the output is  0.5000579711253345\n",
      "variance of the output is  0.12899697446114514\n",
      "fitting a constant\n",
      "Train MSE 0.12895278161838591\n",
      "Test MSE 0.12939480808467343\n",
      "Train R2 0.0\n",
      "Test R2 -7.576767616646052e-06\n",
      "Test bias 0.12939480808467343\n",
      "Test model variance 0.0\n",
      "fitting a 10th order polynomial\n",
      "Train MSE 0.12898598474194922\n",
      "Test MSE 0.12904050584510732\n",
      "Train R2 5.428390186845711e-05\n",
      "Test R2 -6.981393009586334e-05\n",
      "Test bias 0.1290333143703435\n",
      "Test model variance 7.456126505237871e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f29fe96d820>]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 1000 #number of data points along each axis. Total data points = n*n\n",
    "x1 = np.linspace(0,1,n)\n",
    "x2 = np.linspace(0,1,n)\n",
    "xx1, xx2 = np.meshgrid(x1, x2)\n",
    "xx1 = xx1.reshape((n*n),1)\n",
    "xx2 = xx2.reshape((n*n),1)\n",
    "\n",
    "var = np.array([0.1, 0.2, 0.3, 0.4, 0.5])\n",
    "MSE = np.zeros(len(var))\n",
    "\n",
    "for ind, variance in enumerate(var):\n",
    "\n",
    "    y = np.random.normal(loc=0.5, scale = variance, size=xx1.shape)\n",
    "    y[np.where(y>1.0)] = 1.0\n",
    "    y[np.where(y<0.0)] = 0.0\n",
    "\n",
    "    print(\"mean of the output is \", np.mean(y))\n",
    "    print(\"variance of the output is \", np.var(y))\n",
    "\n",
    "    print(\"fitting a constant\")\n",
    "    linear_reg = linear_regression.linear_regression2D(xx1, xx2, y) \n",
    "    linear_reg.apply_leastsquares(order=0, test_ratio=0.1, reg_method=\"ols\")\n",
    "\n",
    "    print(\"Train MSE\", linear_reg.trainMSE)\n",
    "    print(\"Test MSE\", linear_reg.testMSE)\n",
    "    print(\"Train R2\", linear_reg.trainR2)\n",
    "    print(\"Test R2\", linear_reg.testR2)\n",
    "    print(\"Test bias\", linear_reg.testbias)\n",
    "    print(\"Test model variance\", linear_reg.testvar)\n",
    "\n",
    "    print(\"fitting a 10th order polynomial\")\n",
    "    linear_reg.apply_leastsquares(order=10, test_ratio=0.1, reg_method=\"ols\")\n",
    "\n",
    "    print(\"Train MSE\", linear_reg.trainMSE)\n",
    "    print(\"Test MSE\", linear_reg.testMSE)\n",
    "    print(\"Train R2\", linear_reg.trainR2)\n",
    "    print(\"Test R2\", linear_reg.testR2)\n",
    "    print(\"Test bias\", linear_reg.testbias)\n",
    "    print(\"Test model variance\", linear_reg.testvar)\n",
    "    \n",
    "    MSE[ind] = linear_reg.testMSE\n",
    "\n",
    "plt.plot(var, MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e445f2ee",
   "metadata": {},
   "source": [
    "## Fitting a 2D gaussian function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3973f625",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8b5a7a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-24T09:59:44.885373Z",
     "start_time": "2021-11-24T09:59:44.885362Z"
    }
   },
   "source": [
    "# Bias Variance Tradeoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7d153594",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T14:30:23.502459Z",
     "start_time": "2021-11-30T14:30:23.486572Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data_linear_regression/test_ratio_array.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-9d3466092ca2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnum_points\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data_linear_regression/num_points.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnoise_var\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data_linear_regression/noise_var.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtest_ratio_array\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data_linear_regression/test_ratio_array.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mridge_lambda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data_linear_regression/ridge_lambda.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mk_folds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data_linear_regression/k_folds.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    415\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data_linear_regression/test_ratio_array.npy'"
     ]
    }
   ],
   "source": [
    "#loading data\n",
    "method = \"ols\"\n",
    "order=np.load(\"data_linear_regression/order.npy\")\n",
    "num_points=np.load(\"data_linear_regression/num_points.npy\")\n",
    "noise_var=np.load(\"data_linear_regression/noise_var.npy\")\n",
    "test_ratio_array=np.load(\"data_linear_regression/test_ratio_array.npy\")\n",
    "ridge_lambda=np.load(\"data_linear_regression/ridge_lambda.npy\")\n",
    "k_folds=np.load(\"data_linear_regression/k_folds.npy\")\n",
    "n_boots=np.load(\"data_linear_regression/n_boots.npy\")\n",
    "train_MSE=np.load(\"data_linear_regression/train_MSE\"+method+\".npy\")\n",
    "test_MSE=np.load(\"data_linear_regression/test_MSE\"+method+\".npy\")\n",
    "train_R2=np.load(\"data_linear_regression/train_R2\"+method+\".npy\")\n",
    "test_R2=np.load(\"data_linear_regression/test_R2\"+method+\".npy\")\n",
    "test_bias=np.load(\"data_linear_regression/test_bias\"+method+\".npy\")\n",
    "test_var=np.load(\"data_linear_regression/test_variance\"+method+\".npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ce159b",
   "metadata": {},
   "source": [
    "For Ordinary least squares, we find the bias variance tradeoff as a function of model complexity: order of polynomial. We determine it for fixed test ratio and noise level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffb0ff4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T14:30:24.969721Z",
     "start_time": "2021-11-30T14:30:24.625082Z"
    }
   },
   "outputs": [],
   "source": [
    "r_ind = 1 # r=0.1\n",
    "n_ind = 3 # n=100\n",
    "noise_ind = 2 #noise variance = 0.5\n",
    "ols_bias = test_bias[:, n_ind, noise_ind, r_ind, 0, 0, 0]\n",
    "ols_var = test_var[:, n_ind, noise_ind, r_ind, 0, 0, 0]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(order, ols_bias, 'k', label = \"bias\")\n",
    "ax.plot(order, ols_var, 'b', label = \"variance\")\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"order of ploynomial\")\n",
    "\n",
    "def plotOLSstats(num_point, test_ratio, var):\n",
    "    n_ind = 0\n",
    "    for i in range(len(num_points)):\n",
    "        if num_point == num_points[i]:\n",
    "            n_ind = i\n",
    "    r_ind = 0\n",
    "    for i in range(len(test_ratio_array)):\n",
    "        if test_ratio == test_ratio_array[i]:\n",
    "            r_ind = i\n",
    "    noise_ind = 0\n",
    "    for i in range(len(noise_var)):\n",
    "        if var == noise_var[i]:\n",
    "            r_ind = i\n",
    "            \n",
    "    ols_bias = test_bias[:, n_ind, noise_ind, r_ind, 0, 0, 0]\n",
    "    ols_var = test_var[:, n_ind, noise_ind, r_ind, 0, 0, 0]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(order, ols_bias, 'k', label = \"bias\")\n",
    "    ax.plot(order, ols_var, 'b', label = \"variance\")\n",
    "    ax.legend()\n",
    "    ax.set_xlabel(\"order of ploynomial\")\n",
    "    \n",
    "widget.interact(plotOLSstats, num_point=num_points.tolist(), \n",
    "                test_ratio=test_ratio_array.tolist(), var=noise_var.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc103f1c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T14:21:22.776097Z",
     "start_time": "2021-11-30T14:21:22.658631Z"
    }
   },
   "outputs": [],
   "source": [
    "r_ind = 0 # r=0.1\n",
    "n_ind = 0 # n=100\n",
    "noise_ind = 4 #noise variance = 0.5\n",
    "ols_testMSE = test_MSE[:, n_ind, noise_ind, r_ind, 0, 0, 0]\n",
    "ols_trainMSE = train_MSE[:, n_ind, noise_ind, r_ind, 0, 0, 0]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(order, ols_testMSE, 'k')\n",
    "ax.plot(order, ols_trainMSE, 'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e1b7f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T14:21:23.853004Z",
     "start_time": "2021-11-30T14:21:23.734143Z"
    }
   },
   "outputs": [],
   "source": [
    "r_ind = 1 # r=0.1\n",
    "n_ind = 3 # n=100\n",
    "noise_ind = 2 #noise variance = 0.5\n",
    "ols_bias = test_bias[:, n_ind, noise_ind, r_ind, 0, 0, 0]\n",
    "ols_var = test_var[:, n_ind, noise_ind, r_ind, 0, 0, 0]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(order, ols_bias, 'k')\n",
    "ax.plot(order, ols_var, 'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7d30ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-29T16:23:59.115233Z",
     "start_time": "2021-11-29T16:23:58.979026Z"
    }
   },
   "outputs": [],
   "source": [
    "r_ind = 1 # r=0.1\n",
    "n_ind = 3 # n=100\n",
    "noise_ind = 2 #noise variance = 0.5\n",
    "ols_testMSE = test_MSE[:, n_ind, noise_ind, r_ind, 0, 0, 0]\n",
    "ols_trainMSE = train_MSE[:, n_ind, noise_ind, r_ind, 0, 0, 0]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(order, ols_testMSE, 'k', label=\"testMSE\")\n",
    "ax.plot(order, ols_trainMSE, 'b', label=\"trainMSE\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d7aaff",
   "metadata": {},
   "source": [
    "## Functions of model complexity for OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78424b91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T15:38:08.351019Z",
     "start_time": "2021-11-30T15:38:06.721288Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def OLS_study(n, var, r):\n",
    "    n=np.array([n])\n",
    "    var=np.array([var])\n",
    "    r=np.array([r])\n",
    "    print(var)\n",
    "    order = np.arange(1,15)\n",
    "    method=\"ols\"\n",
    "    train_MSE, test_MSE, train_R2, test_R2, test_bias, test_var = apply_regression(order, n, noise_var = var, test_ratio_array=r)\n",
    "    print(order.shape)\n",
    "    fig, ax = plt.subplots(3,1, figsize=(8,8))\n",
    "    ax[0].plot(order, train_MSE[:,0,0,0,0,0,0,0], 'k', label=\"train MSE\")\n",
    "    ax[0].plot(order, test_MSE[:,0,0,0,0,0,0,0], 'b', label=\"test MSE\")\n",
    "    ax[1].plot(order, test_bias[:,0,0,0,0,0,0,0], 'k', label=\"bias\")\n",
    "    ax[1].plot(order, test_var[:,0,0,0,0,0,0,0], 'b', label=\"variance\")\n",
    "    ax[2].plot(order, train_R2[:,0,0,0,0,0,0,0], 'k', label=\"train R2\")\n",
    "    ax[2].plot(order, test_R2[:,0,0,0,0,0,0,0], 'b', label=\"test R2\")\n",
    "    ax[0].legend()\n",
    "    ax[1].legend()\n",
    "    ax[2].legend()\n",
    "widget.interact(OLS_study, n=(10,200,10), var=(0,1,0.1), r=(0.1,0.5,0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9dc0f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso_study(n, var, r, lam):\n",
    "    n = np.array([n])\n",
    "    var = np.array([var])\n",
    "    r = np.array([r])\n",
    "    lam = np.array([lam])\n",
    "    order = np.arange(1,11)\n",
    "    method = \"lasso\"\n",
    "    train_MSE, test_MSE, train_R2, test_R2, test_bias, test_var = apply_regression(order, n, var,\n",
    "                                                                                   r, lasso_lambda=lam, reg_type=\"lasso\")\n",
    "    fig, ax = plt.subplots(3,1, figsize=(8,8))\n",
    "    ax[0].plot(order, train_MSE[:,0,0,0,0,0,0,0], 'k', label=\"train MSE\")\n",
    "    ax[0].plot(order, test_MSE[:,0,0,0,0,0,0,0], 'b', label=\"test MSE\")\n",
    "    ax[1].plot(order, test_bias[:,0,0,0,0,0,0,0], 'k', label=\"bias\")\n",
    "    ax[1].plot(order, test_var[:,0,0,0,0,0,0,0], 'b', label=\"variance\")\n",
    "    ax[2].plot(order, train_R2[:,0,0,0,0,0,0,0], 'k', label=\"train R2\")\n",
    "    ax[2].plot(order, test_R2[:,0,0,0,0,0,0,0], 'b', label=\"test R2\")\n",
    "    ax[0].legend()\n",
    "    ax[1].legend()\n",
    "    ax[2].legend()\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "widget.interact(lasso_study, n=(10,50,10), var=(0,1,0.25), r=(0.1,0.5,0.1), lam=np.logspace(-5,0,11).tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b2cb87",
   "metadata": {},
   "source": [
    "# Visualisation of Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67169f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100 #number of data points along each axis. Total data points = n*n\n",
    "x1 = np.linspace(0,1,n)\n",
    "x2 = np.linspace(0,1,n)\n",
    "xx1, xx2 = np.meshgrid(x1, x2)\n",
    "xx1 = xx1.reshape((n*n),1)\n",
    "xx2 = xx2.reshape((n*n),1)\n",
    "\n",
    "y = franke.Franke(xx1, xx2, noise_var=0.4) #zero mean gaussian noise\n",
    "xx1 = xx1.reshape([n,n])\n",
    "xx2 = xx2.reshape([n,n])\n",
    "\n",
    "y = y.reshape(n,n)\n",
    "\n",
    "#rescaling y\n",
    "y = (y-np.amin(y))/(np.amax(y)-np.amin(y))\n",
    "\n",
    "fig, ax = plt.subplots(subplot_kw={\"projection\": \"3d\"}, figsize=(8,8))\n",
    "#ax.plot_surface(xx1, xx2, y, rstride=8, cstride=8, alpha=0.2, cmap=cm.coolwarm)\n",
    "cset = ax.contour(xx1, xx2, y, zdir='z', offset=0, cmap=cm.coolwarm)\n",
    "cset = ax.contour(xx1, xx2, y, zdir='x', offset=0, cmap=cm.coolwarm_r)\n",
    "cset = ax.contour(xx1, xx2, y, zdir='y', offset=1, cmap=cm.coolwarm_r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8bbd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 300 #number of data points along each axis. Total data points = n*n\n",
    "x1 = np.linspace(0,1,n)\n",
    "x2 = np.linspace(0,1,n)\n",
    "xx1, xx2 = np.meshgrid(x1, x2)\n",
    "xx1 = xx1.reshape((n*n),1)\n",
    "xx2 = xx2.reshape((n*n),1)\n",
    "\n",
    "noise_var = np.array([0.0, 0.1, 0.2, 0.3, 0.4, 0.5])\n",
    "\n",
    "fig, ax = plt.subplots(2, 3,subplot_kw={\"projection\": \"3d\"}, figsize=(12,8))\n",
    "for ind, var in enumerate(noise_var):\n",
    "    y = franke.Franke(xx1, xx2, noise_var=var) #zero mean gaussian noise\n",
    "    xx1 = xx1.reshape([n,n])\n",
    "    xx2 = xx2.reshape([n,n])\n",
    "\n",
    "    y = y.reshape(n,n)\n",
    "    #rescaling y\n",
    "    y = (y-np.amin(y))/(np.amax(y)-np.amin(y))\n",
    "    \n",
    "    if(ind<3): a = 0 \n",
    "    else: a = 1\n",
    "\n",
    "    #ax[a, ind%3].plot_surface(xx1, xx2, y, rstride=8, cstride=8, alpha=0.2, cmap=cm.coolwarm)\n",
    "    ax[a, ind%3].title.set_text(str(var))\n",
    "    cset = ax[a, ind%3].contourf(xx1, xx2, y, zdir='z', offset=0, cmap=cm.coolwarm)\n",
    "    cset = ax[a, ind%3].contour(xx1, xx2, y, zdir='x', offset=0, cmap=cm.coolwarm_r)\n",
    "    cset = ax[a, ind%3].contour(xx1, xx2, y, zdir='y', offset=1, cmap=cm.coolwarm_r)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e714231",
   "metadata": {},
   "source": [
    "We can see above that for variance > 0.2 the noisy franke function appears incomprehensible compared to the noiseless one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f65a1fc",
   "metadata": {},
   "source": [
    "# Corrections to bias\n",
    "\n",
    "When calculating bias we have to remove the variance of the noise. However, as we are scaling the noise before we add it to the data, our true variance is different from the variance we used to find the noise to Franke data. \n",
    "\n",
    "Now, we have two options. \n",
    "1: Scaling \"y\" doesn't affect the bias.\n",
    "2: Scaling \"y\" does affect the bias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fd96be",
   "metadata": {},
   "source": [
    "## Scaling \"y\" doesn't affect the bias calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a639890",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100 #number of data points along each axis. Total data points = n*n\n",
    "x1 = np.linspace(0,1,n)\n",
    "x2 = np.linspace(0,1,n)\n",
    "xx1, xx2 = np.meshgrid(x1, x2)\n",
    "xx1 = xx1.reshape((n*n),1)\n",
    "xx2 = xx2.reshape((n*n),1)\n",
    "\n",
    "design_var = np.arange(0.0,2.0,0.1)\n",
    "true_var = np.zeros(len(design_var))\n",
    "for i, v in enumerate(var):\n",
    "    y, true_var[i] = franke.Franke_and_biascorrection(xx1, xx2, noise_var=v) #zero mean gaussian noise has variance = var    \n",
    "print(true_var)\n",
    "print(design_var)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(design_var, true_var)\n",
    "ax.set_xlabel(\"noise variance\")\n",
    "ax.set_ylabel(\"true variance\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb0cc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def OLS_study(n, var, r):\n",
    "    n=np.array([n])\n",
    "    print(np.ceil((var-0.001)*10))\n",
    "    err = true_var[int(np.ceil((var-0.001)*10))]\n",
    "    \n",
    "    var=np.array([var])\n",
    "    r=np.array([r])\n",
    "    print(var)\n",
    "    order = np.arange(1,15)\n",
    "    method=\"ols\"\n",
    "    train_MSE, test_MSE, train_R2, test_R2, test_bias, test_var = apply_regression(order, n, noise_var = var, test_ratio_array=r)\n",
    "    print(order.shape)\n",
    "    fig, ax = plt.subplots(3,1, figsize=(8,8))\n",
    "    ax[0].plot(order, train_MSE[:,0,0,0,0,0,0,0], 'k', label=\"train MSE\")\n",
    "    ax[0].plot(order, test_MSE[:,0,0,0,0,0,0,0], 'b', label=\"test MSE\")\n",
    "    ax[1].plot(order, test_bias[:,0,0,0,0,0,0,0]-err, 'k', label=\"bias\")\n",
    "    ax[1].plot(order, test_var[:,0,0,0,0,0,0,0], 'b', label=\"variance\")\n",
    "    ax[2].plot(order, train_R2[:,0,0,0,0,0,0,0], 'k', label=\"train R2\")\n",
    "    ax[2].plot(order, test_R2[:,0,0,0,0,0,0,0], 'b', label=\"test R2\")\n",
    "    ax[0].legend()\n",
    "    ax[1].legend()\n",
    "    ax[2].legend()\n",
    "widget.interact(OLS_study, n=(10,200,10), var=(0,1,0.1), r=(0.1,0.5,0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3d7b45",
   "metadata": {},
   "source": [
    "## Scaling \"y\" does affect the bias calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26aec4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100 #number of data points along each axis. Total data points = n*n\n",
    "x1 = np.linspace(0,1,n)\n",
    "x2 = np.linspace(0,1,n)\n",
    "xx1, xx2 = np.meshgrid(x1, x2)\n",
    "xx1 = xx1.reshape((n*n),1)\n",
    "xx2 = xx2.reshape((n*n),1)\n",
    "\n",
    "design_var = np.arange(0.0,2.0,0.1)\n",
    "true_var = np.zeros(len(design_var))\n",
    "for i, v in enumerate(var):\n",
    "    y, true_var[i] = franke.Franke_and_biascorrection(xx1, xx2, noise_var=v) #zero mean gaussian noise has variance = var    \n",
    "print(np.amax(y))\n",
    "true_var = true_var/np.amax(y)\n",
    "print(true_var)\n",
    "print(design_var)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(design_var, true_var)\n",
    "ax.set_xlabel(\"noise variance\")\n",
    "ax.set_ylabel(\"true variance\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5f1044",
   "metadata": {},
   "outputs": [],
   "source": [
    "def OLS_study(n, var, r):\n",
    "    n=np.array([n])\n",
    "    print(np.ceil((var-0.001)*10))\n",
    "    err = true_var[int(np.ceil((var-0.001)*10))]\n",
    "    \n",
    "    var=np.array([var])\n",
    "    r=np.array([r])\n",
    "    print(var)\n",
    "    order = np.arange(1,15)\n",
    "    method=\"ols\"\n",
    "    train_MSE, test_MSE, train_R2, test_R2, test_bias, test_var = apply_regression(order, n, noise_var = var, test_ratio_array=r)\n",
    "    print(order.shape)\n",
    "    fig, ax = plt.subplots(3,1, figsize=(8,8))\n",
    "    ax[0].plot(order, train_MSE[:,0,0,0,0,0,0,0], 'k', label=\"train MSE\")\n",
    "    ax[0].plot(order, test_MSE[:,0,0,0,0,0,0,0], 'b', label=\"test MSE\")\n",
    "    ax[1].plot(order, test_bias[:,0,0,0,0,0,0,0]-err, 'k', label=\"bias\")\n",
    "    ax[1].plot(order, test_var[:,0,0,0,0,0,0,0], 'b', label=\"variance\")\n",
    "    ax[2].plot(order, train_R2[:,0,0,0,0,0,0,0], 'k', label=\"train R2\")\n",
    "    ax[2].plot(order, test_R2[:,0,0,0,0,0,0,0], 'b', label=\"test R2\")\n",
    "    ax[0].legend()\n",
    "    ax[1].legend()\n",
    "    ax[2].legend()\n",
    "widget.interact(OLS_study, n=(10,200,10), var=(0,1,0.1), r=(0.1,0.5,0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f92a43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
