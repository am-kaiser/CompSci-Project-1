{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "983ce2ee",
   "metadata": {},
   "source": [
    "# Analysis of the Wisconsin Breast Cancer Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "05278d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a5ff154b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import own modules\n",
    "from regression_analysis.fit_model import logistic_regression, apply_logistic_regression\n",
    "\n",
    "# Import other packages\n",
    "import pandas as pd\n",
    "import ipywidgets as widget\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2c0939",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "831f2513",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99000</td>\n",
       "      <td>10.38000</td>\n",
       "      <td>122.80000</td>\n",
       "      <td>1001.00000</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38000</td>\n",
       "      <td>17.33000</td>\n",
       "      <td>184.60000</td>\n",
       "      <td>2019.00000</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.71190</td>\n",
       "      <td>0.26540</td>\n",
       "      <td>0.46010</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57000</td>\n",
       "      <td>17.77000</td>\n",
       "      <td>132.90000</td>\n",
       "      <td>1326.00000</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99000</td>\n",
       "      <td>23.41000</td>\n",
       "      <td>158.80000</td>\n",
       "      <td>1956.00000</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.24160</td>\n",
       "      <td>0.18600</td>\n",
       "      <td>0.27500</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69000</td>\n",
       "      <td>21.25000</td>\n",
       "      <td>130.00000</td>\n",
       "      <td>1203.00000</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57000</td>\n",
       "      <td>25.53000</td>\n",
       "      <td>152.50000</td>\n",
       "      <td>1709.00000</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.45040</td>\n",
       "      <td>0.24300</td>\n",
       "      <td>0.36130</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42000</td>\n",
       "      <td>20.38000</td>\n",
       "      <td>77.58000</td>\n",
       "      <td>386.10000</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91000</td>\n",
       "      <td>26.50000</td>\n",
       "      <td>98.87000</td>\n",
       "      <td>567.70000</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.68690</td>\n",
       "      <td>0.25750</td>\n",
       "      <td>0.66380</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29000</td>\n",
       "      <td>14.34000</td>\n",
       "      <td>135.10000</td>\n",
       "      <td>1297.00000</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54000</td>\n",
       "      <td>16.67000</td>\n",
       "      <td>152.20000</td>\n",
       "      <td>1575.00000</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.40000</td>\n",
       "      <td>0.16250</td>\n",
       "      <td>0.23640</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>926424</td>\n",
       "      <td>M</td>\n",
       "      <td>21.56000</td>\n",
       "      <td>22.39000</td>\n",
       "      <td>142.00000</td>\n",
       "      <td>1479.00000</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>...</td>\n",
       "      <td>25.45000</td>\n",
       "      <td>26.40000</td>\n",
       "      <td>166.10000</td>\n",
       "      <td>2027.00000</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.41070</td>\n",
       "      <td>0.22160</td>\n",
       "      <td>0.20600</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>926682</td>\n",
       "      <td>M</td>\n",
       "      <td>20.13000</td>\n",
       "      <td>28.25000</td>\n",
       "      <td>131.20000</td>\n",
       "      <td>1261.00000</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>...</td>\n",
       "      <td>23.69000</td>\n",
       "      <td>38.25000</td>\n",
       "      <td>155.00000</td>\n",
       "      <td>1731.00000</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.32150</td>\n",
       "      <td>0.16280</td>\n",
       "      <td>0.25720</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>926954</td>\n",
       "      <td>M</td>\n",
       "      <td>16.60000</td>\n",
       "      <td>28.08000</td>\n",
       "      <td>108.30000</td>\n",
       "      <td>858.10000</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>...</td>\n",
       "      <td>18.98000</td>\n",
       "      <td>34.12000</td>\n",
       "      <td>126.70000</td>\n",
       "      <td>1124.00000</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.34030</td>\n",
       "      <td>0.14180</td>\n",
       "      <td>0.22180</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>927241</td>\n",
       "      <td>M</td>\n",
       "      <td>20.60000</td>\n",
       "      <td>29.33000</td>\n",
       "      <td>140.10000</td>\n",
       "      <td>1265.00000</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>...</td>\n",
       "      <td>25.74000</td>\n",
       "      <td>39.42000</td>\n",
       "      <td>184.60000</td>\n",
       "      <td>1821.00000</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.93870</td>\n",
       "      <td>0.26500</td>\n",
       "      <td>0.40870</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>92751</td>\n",
       "      <td>B</td>\n",
       "      <td>7.76000</td>\n",
       "      <td>24.54000</td>\n",
       "      <td>47.92000</td>\n",
       "      <td>181.00000</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.45600</td>\n",
       "      <td>30.37000</td>\n",
       "      <td>59.16000</td>\n",
       "      <td>268.60000</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.28710</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0      842302         M     17.99000      10.38000       122.80000 1001.00000   \n",
       "1      842517         M     20.57000      17.77000       132.90000 1326.00000   \n",
       "2    84300903         M     19.69000      21.25000       130.00000 1203.00000   \n",
       "3    84348301         M     11.42000      20.38000        77.58000  386.10000   \n",
       "4    84358402         M     20.29000      14.34000       135.10000 1297.00000   \n",
       "..        ...       ...          ...           ...             ...        ...   \n",
       "564    926424         M     21.56000      22.39000       142.00000 1479.00000   \n",
       "565    926682         M     20.13000      28.25000       131.20000 1261.00000   \n",
       "566    926954         M     16.60000      28.08000       108.30000  858.10000   \n",
       "567    927241         M     20.60000      29.33000       140.10000 1265.00000   \n",
       "568     92751         B      7.76000      24.54000        47.92000  181.00000   \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0            0.11840           0.27760         0.30010              0.14710   \n",
       "1            0.08474           0.07864         0.08690              0.07017   \n",
       "2            0.10960           0.15990         0.19740              0.12790   \n",
       "3            0.14250           0.28390         0.24140              0.10520   \n",
       "4            0.10030           0.13280         0.19800              0.10430   \n",
       "..               ...               ...             ...                  ...   \n",
       "564          0.11100           0.11590         0.24390              0.13890   \n",
       "565          0.09780           0.10340         0.14400              0.09791   \n",
       "566          0.08455           0.10230         0.09251              0.05302   \n",
       "567          0.11780           0.27700         0.35140              0.15200   \n",
       "568          0.05263           0.04362         0.00000              0.00000   \n",
       "\n",
       "     ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       "0    ...      25.38000       17.33000        184.60000  2019.00000   \n",
       "1    ...      24.99000       23.41000        158.80000  1956.00000   \n",
       "2    ...      23.57000       25.53000        152.50000  1709.00000   \n",
       "3    ...      14.91000       26.50000         98.87000   567.70000   \n",
       "4    ...      22.54000       16.67000        152.20000  1575.00000   \n",
       "..   ...           ...            ...              ...         ...   \n",
       "564  ...      25.45000       26.40000        166.10000  2027.00000   \n",
       "565  ...      23.69000       38.25000        155.00000  1731.00000   \n",
       "566  ...      18.98000       34.12000        126.70000  1124.00000   \n",
       "567  ...      25.74000       39.42000        184.60000  1821.00000   \n",
       "568  ...       9.45600       30.37000         59.16000   268.60000   \n",
       "\n",
       "     smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0             0.16220            0.66560          0.71190   \n",
       "1             0.12380            0.18660          0.24160   \n",
       "2             0.14440            0.42450          0.45040   \n",
       "3             0.20980            0.86630          0.68690   \n",
       "4             0.13740            0.20500          0.40000   \n",
       "..                ...                ...              ...   \n",
       "564           0.14100            0.21130          0.41070   \n",
       "565           0.11660            0.19220          0.32150   \n",
       "566           0.11390            0.30940          0.34030   \n",
       "567           0.16500            0.86810          0.93870   \n",
       "568           0.08996            0.06444          0.00000   \n",
       "\n",
       "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                 0.26540         0.46010                  0.11890  \n",
       "1                 0.18600         0.27500                  0.08902  \n",
       "2                 0.24300         0.36130                  0.08758  \n",
       "3                 0.25750         0.66380                  0.17300  \n",
       "4                 0.16250         0.23640                  0.07678  \n",
       "..                    ...             ...                      ...  \n",
       "564               0.22160         0.20600                  0.07115  \n",
       "565               0.16280         0.25720                  0.06637  \n",
       "566               0.14180         0.22180                  0.07820  \n",
       "567               0.26500         0.40870                  0.12400  \n",
       "568               0.00000         0.28710                  0.07039  \n",
       "\n",
       "[569 rows x 32 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "data = pd.read_csv('data_logistic_regression/data.csv', sep=',')\n",
    "# Display data\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c166b5f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 32 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       569 non-null    int64  \n",
      " 1   diagnosis                569 non-null    object \n",
      " 2   radius_mean              569 non-null    float64\n",
      " 3   texture_mean             569 non-null    float64\n",
      " 4   perimeter_mean           569 non-null    float64\n",
      " 5   area_mean                569 non-null    float64\n",
      " 6   smoothness_mean          569 non-null    float64\n",
      " 7   compactness_mean         569 non-null    float64\n",
      " 8   concavity_mean           569 non-null    float64\n",
      " 9   concave points_mean      569 non-null    float64\n",
      " 10  symmetry_mean            569 non-null    float64\n",
      " 11  fractal_dimension_mean   569 non-null    float64\n",
      " 12  radius_se                569 non-null    float64\n",
      " 13  texture_se               569 non-null    float64\n",
      " 14  perimeter_se             569 non-null    float64\n",
      " 15  area_se                  569 non-null    float64\n",
      " 16  smoothness_se            569 non-null    float64\n",
      " 17  compactness_se           569 non-null    float64\n",
      " 18  concavity_se             569 non-null    float64\n",
      " 19  concave points_se        569 non-null    float64\n",
      " 20  symmetry_se              569 non-null    float64\n",
      " 21  fractal_dimension_se     569 non-null    float64\n",
      " 22  radius_worst             569 non-null    float64\n",
      " 23  texture_worst            569 non-null    float64\n",
      " 24  perimeter_worst          569 non-null    float64\n",
      " 25  area_worst               569 non-null    float64\n",
      " 26  smoothness_worst         569 non-null    float64\n",
      " 27  compactness_worst        569 non-null    float64\n",
      " 28  concavity_worst          569 non-null    float64\n",
      " 29  concave points_worst     569 non-null    float64\n",
      " 30  symmetry_worst           569 non-null    float64\n",
      " 31  fractal_dimension_worst  569 non-null    float64\n",
      "dtypes: float64(30), int64(1), object(1)\n",
      "memory usage: 142.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b42f360",
   "metadata": {},
   "source": [
    "For the design matrix we drop the column id and diagnosis from the data. The id is not important for making predictions and the diagnosis is what we want to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b379e5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform diagnosis to 0 and 1\n",
    "data.diagnosis = [1 if each == \"M\" else 0 for each in data.diagnosis]\n",
    "\n",
    "# Create design matrix and normalise it\n",
    "X = logistic_regression.design_matrix(data)\n",
    "X_norm = logistic_regression.normalise_data(X)\n",
    "\n",
    "# Define to be predicted values\n",
    "y = data.diagnosis.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7691ea45",
   "metadata": {},
   "source": [
    "## Perform Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "49eaf7a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78a612967e34437694d7ecb4d0ca158f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='reg_method', options=('logistic_sgd', 'logistic_scikit', 'svm'), v…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.perform_simple_logistic_regression(reg_method, sample_method, data_set)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def perform_simple_logistic_regression(reg_method, sample_method, data_set):\n",
    "    \n",
    "    logistic_regression_object = logistic_regression.LogisticRegression(X_norm, y)\n",
    "    \n",
    "    if sample_method == \"crossvalidation\":\n",
    "        logistic_regression_object.apply_logistic_regression_crossvalidation(reg_method=reg_method)\n",
    "    else:\n",
    "        logistic_regression_object.apply_logistic_regression(reg_method=reg_method)\n",
    "\n",
    "    if data_set == 'train':\n",
    "        sns.heatmap(logistic_regression_object.train_confusion_matrix, annot=True, cmap=\"mako\", yticklabels=['is_malignant', 'is_benign'],\n",
    "                    xticklabels=['predicted_malignent', 'predicted_benign'])\n",
    "    else:\n",
    "        sns.heatmap(logistic_regression_object.test_confusion_matrix, annot=True, cmap=\"mako\", yticklabels=['is_malignant', 'is_benign'],\n",
    "                    xticklabels=['predicted_malignent', 'predicted_benign'])\n",
    "    \n",
    "widget.interact(perform_simple_logistic_regression, reg_method=[\"logistic_sgd\", \"logistic_scikit\", \"svm\"], \n",
    "                sample_method=[None, \"crossvalidation\"], data_set=['train', 'test'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f250dc04",
   "metadata": {},
   "source": [
    "## Compare Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2d15bf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For all methods we apply the following parameters\n",
    "num_points = np.array([25, 50, 75, 100])\n",
    "test_ratio = np.round(np.arange(1,5)*0.1, 2)\n",
    "\n",
    "k_folds = np.array([5, 10], dtype=int)\n",
    "\n",
    "l2_lambda = np.array([0.001, 0.01, 0.1, 1.0])\n",
    "\n",
    "# Parameters for stochastic gradient descent\n",
    "learn_rate = np.array([0.001, 0.01, 0.1, 1.0])\n",
    "num_min_batch = np.array([2, 5, 10, 50])\n",
    "epochs = np.array([10, 50, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "138ee020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save values in numpy file format\n",
    "np.save(\"data_logistic_regression/num_points.npy\", num_points)\n",
    "np.save(\"data_logistic_regression/test_ratio.npy\", test_ratio)\n",
    "np.save(\"data_logistic_regression/k_folds.npy\", k_folds)\n",
    "np.save(\"data_logistic_regression/l2_lambda.npy\", l2_lambda)\n",
    "np.save(\"data_logistic_regression/learn_rates.npy\", learn_rate)\n",
    "np.save(\"data_logistic_regression/num_min_batches.npy\", num_min_batch)\n",
    "np.save(\"data_logistic_regression/epochs.npy\", epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3d1632cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amandink/Documents/01_PhD/01_Code/CompSci-Project-1/regression_analysis/utils/stochastic_gradient_descent.py:21: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-z))\n",
      "/home/amandink/Documents/01_PhD/01_Code/CompSci-Project-1/regression_analysis/utils/stochastic_gradient_descent.py:33: RuntimeWarning: overflow encountered in matmul\n",
      "  gradient = (-1) * X.T @ (y - sigmoid_func(X @ beta)) - lmbda*beta\n",
      "/home/amandink/Documents/01_PhD/01_Code/CompSci-Project-1/regression_analysis/utils/stochastic_gradient_descent.py:61: RuntimeWarning: overflow encountered in subtract\n",
      "  vector -= descend\n",
      "/home/amandink/Documents/01_PhD/01_Code/CompSci-Project-1/regression_analysis/utils/stochastic_gradient_descent.py:33: RuntimeWarning: invalid value encountered in matmul\n",
      "  gradient = (-1) * X.T @ (y - sigmoid_func(X @ beta)) - lmbda*beta\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 4, 4, 1, 4, 4, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amandink/anaconda3/envs/CompSci-Project-1/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/amandink/anaconda3/envs/CompSci-Project-1/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 4, 4, 1, 4, 4, 3)\n",
      "(4, 4, 4, 1, 4, 4, 3)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 31)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_25613/170602241.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0ml2_lambda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# Calculate statistical indicators\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     train_accuracy, test_accuracy = apply_logistic_regression.apply_regression(num_points,\n\u001b[0m\u001b[1;32m     17\u001b[0m                                                                                    \u001b[0mtest_ratios\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_ratio\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                                                                                    \u001b[0mk_folds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk_folds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/01_PhD/01_Code/CompSci-Project-1/regression_analysis/fit_model/apply_logistic_regression.py\u001b[0m in \u001b[0;36mapply_regression\u001b[0;34m(num_points, test_ratios, reg_type, l2_lambda, k_folds, learn_rate, num_min_batch, epochs)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreg_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"logistic_scikit_crossvalidation\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m                 \u001b[0mlogistic_reg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_logistic_regression_crossvalidation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkfolds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"logistic_scikit\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m                 \u001b[0mtrain_acc_arr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpoints_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogistic_reg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0mtest_acc_arr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpoints_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogistic_reg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/01_PhD/01_Code/CompSci-Project-1/regression_analysis/fit_model/logistic_regression.py\u001b[0m in \u001b[0;36mapply_logistic_regression_crossvalidation\u001b[0;34m(self, kfolds, reg_method, lmbda, num_epoch, learn_rate, num_min_batch)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0;31m# finding model parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m             \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_logistic_model_parameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlmbda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_min_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m             \u001b[0;31m# Fit model for test and train data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0my_model_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/01_PhD/01_Code/CompSci-Project-1/regression_analysis/fit_model/logistic_regression.py\u001b[0m in \u001b[0;36mfind_logistic_model_parameter\u001b[0;34m(design_matrix, y_input, method, lam, num_epoch, learn_rate, num_min_batch)\u001b[0m\n\u001b[1;32m     59\u001b[0m                                                                                    num_min_batch=num_min_batch, lmbda=lam)\n\u001b[1;32m     60\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"logistic_scikit\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mparameter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfit_intercept\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdesign_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m  \u001b[0;31m# penalty???\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"svm\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mparameter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdesign_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/CompSci-Project-1/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1506\u001b[0m             \u001b[0m_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1508\u001b[0;31m         X, y = self._validate_data(\n\u001b[0m\u001b[1;32m   1509\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/CompSci-Project-1/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    574\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 576\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    577\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/CompSci-Project-1/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y cannot be None\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 956\u001b[0;31m     X = check_array(\n\u001b[0m\u001b[1;32m    957\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/CompSci-Project-1/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    795\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_samples\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    798\u001b[0m                 \u001b[0;34m\"Found array with %d sample(s) (shape=%s) while a\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m                 \u001b[0;34m\" minimum of %d is required%s.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 31)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "# Define for which methods and resampling techniques the statistical indicators should be calculated\n",
    "\n",
    "methods = [\"logistic_sgd\", \"logistic_sgd_crossvalidation\", \"logistic_scikit\",  \"logistic_scikit_crossvalidation\", \n",
    "           \"svm\", \"svm_crossvalidation\"]\n",
    "# Loop over specified methods\n",
    "for method in methods:\n",
    "    if \"crossvalidation\" in method:\n",
    "        test_ratio_array = np.ones(1)*0.1\n",
    "    else:\n",
    "        k_folds = np.ones(1, dtype=int)\n",
    "    if \"ridge\" not in method:\n",
    "        ridge_lambda = np.ones(1)\n",
    "    if \"sgd\" not in method:\n",
    "        l2_lambda = np.ones(1)\n",
    "    # Calculate statistical indicators\n",
    "    train_accuracy, test_accuracy = apply_logistic_regression.apply_regression(num_points,\n",
    "                                                                                   test_ratios=test_ratio,\n",
    "                                                                                   k_folds=k_folds, \n",
    "                                                                                   l2_lambda=l2_lambda,\n",
    "                                                                                   reg_type=method, \n",
    "                                                                                   learn_rate=learn_rate,\n",
    "                                                                                   num_min_batch=num_min_batch,\n",
    "                                                                                   epochs=epochs)\n",
    "    # Save output\n",
    "    np.save(\"data_logistic_regression/train_accuracy\"+str(method)+\".npy\", train_accuracy)\n",
    "    np.save(\"data_logistic_regression/test_accuracy\"+str(method)+\".npy\", test_accuracy)\n",
    "    # np.save(\"data_logistic_regression/train_confusion_matrix\"+str(method)+\".npy\", train_confusion_matrix)\n",
    "    # np.save(\"data_logistic_regression/test_confusion_matrix\"+str(method)+\".npy\", test_confusion_matrix)\n",
    "    # To track loop progress print size of MSE output\n",
    "    print(train_MSE.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b8bf8705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29af23b9d8da43649dcb8f496ed52a84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='ratio', options=(0.1, 0.2, 0.3, 0.4), value=0.1), Dropdown(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function regression_analysis.fit_model.apply_logistic_regression.plot_stat(ratio=0.1, num=100, stat='test accuracy', method='logistic_sgd', k_fold=1000, l2_lambda=1, learn_rate=0.1, batch=5, epoch=50)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"methods = [\"logistic_sgd\", \"logistic_sgd_crossvalidation\", \"logistic_scikit\",  \"logistic_scikit_crossvalidation\", \n",
    "           \"svm\", \"svm_crossvalidation\"]\"\"\"\n",
    "\n",
    "methods = [\"logistic_sgd\", \"logistic_sgd_crossvalidation\"]\n",
    "stats = [\"train accuracy\", \"test accuracy\"]\n",
    "\n",
    "widget.interact(apply_logistic_regression.plot_stat, ratio=test_ratio.tolist(), num=num_points.tolist(), stat=stats, \n",
    "                method=methods, k_fold=k_folds.tolist(), l2_lambda=l2_lambda.tolist(), learn_rate=learn_rate.tolist(),\n",
    "                batch=num_min_batch.tolist(), epoch=epochs.tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
